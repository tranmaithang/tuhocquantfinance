{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code for run in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from public URL...\n",
      "Loaded AAPL successfully!\n",
      "Loaded JNJ successfully!\n",
      "Loaded JPM successfully!\n",
      "Loaded XOM successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Load Historical Data ---\n",
    "# List of assets to analyze\n",
    "tickers = [\"AAPL\", \"JNJ\", \"JPM\", \"XOM\"]\n",
    "base_url = \"https://raw.githubusercontent.com/tranmaithang/tuhocquantfinance/master/assets/files/market_data/\"\n",
    "\n",
    "all_data = []\n",
    "\n",
    "print(\"Loading data from public URL...\")\n",
    "for ticker in tickers:\n",
    "    # Construct the full URL for each CSV file\n",
    "    url = f\"{base_url}{ticker}.csv\"\n",
    "    try:\n",
    "        # Load the CSV file directly from the URL\n",
    "        temp_df = pd.read_csv(url)\n",
    "        # Ensure Date is datetime if loading from CSV\n",
    "        temp_df['timestamp'] = pd.to_datetime(temp_df['timestamp'])\n",
    "        temp_df['ticker'] = ticker\n",
    "        all_data.append(temp_df)\n",
    "        print(f\"Loaded {ticker} successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {ticker}: {e}\")\n",
    "\n",
    "# Combine all individual dataframes into one master dataframe\n",
    "if all_data:\n",
    "    # Use ignore_index=True to create a fresh index for the merged data\n",
    "    df = pd.concat(all_data, ignore_index=True)\n",
    "else:\n",
    "    print(\"No data was loaded. Please check the URLs or internet connection.\")\n",
    "\n",
    "# Transform to Wide Format for Finance Analysis\n",
    "df_pivot = df.pivot(index='timestamp', columns='ticker', values='close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code for run in Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tickers from: market_data...\n",
      "Successfully loaded: AAPL\n",
      "Successfully loaded: JNJ\n",
      "Successfully loaded: JPM\n",
      "Successfully loaded: XOM\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 1. Load Historical Data ---\n",
    "tickers = [\"AAPL\", \"JNJ\", \"JPM\", \"XOM\"]\n",
    "folder_name = \"market_data\"\n",
    "all_data = []\n",
    "\n",
    "# Load only specified files from the local folder\n",
    "print(f\"Loading tickers from: {folder_name}...\")\n",
    "\n",
    "for ticker in tickers:\n",
    "    # Construct the file path for each ticker\n",
    "    file_name = f\"{ticker}.csv\"\n",
    "    file_path = os.path.join(folder_name, file_name)\n",
    "    \n",
    "    # Check if the file exists before attempting to read it\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            # Read the CSV file\n",
    "            temp_df = pd.read_csv(file_path)\n",
    "             # Ensure Date is datetime if loading from CSV\n",
    "            temp_df['timestamp'] = pd.to_datetime(temp_df['timestamp'])\n",
    "            temp_df['ticker'] = ticker\n",
    "            all_data.append(temp_df)\n",
    "            print(f\"Successfully loaded: {ticker}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_name}: {e}\")\n",
    "    else:\n",
    "        # Inform the user if a requested ticker file is missing\n",
    "        print(f\"Warning: File {file_name} not found in '{folder_name}'. Skipping.\")\n",
    "\n",
    "# Combine all individual dataframes into one master dataframe\n",
    "if all_data:\n",
    "    # Use ignore_index=True to create a fresh index for the merged data\n",
    "    df = pd.concat(all_data, ignore_index=True)\n",
    "else:\n",
    "    print(\"No data was loaded. Please check the URLs or internet connection.\")\n",
    "\n",
    "# Transform to Wide Format for Finance Analysis\n",
    "df_pivot = df.pivot(index='timestamp', columns='ticker', values='close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>JNJ</th>\n",
       "      <th>JPM</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-16 05:00:00</th>\n",
       "      <td>183.63</td>\n",
       "      <td>160.52</td>\n",
       "      <td>167.99</td>\n",
       "      <td>97.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17 05:00:00</th>\n",
       "      <td>182.68</td>\n",
       "      <td>160.43</td>\n",
       "      <td>167.09</td>\n",
       "      <td>96.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-18 05:00:00</th>\n",
       "      <td>188.63</td>\n",
       "      <td>161.21</td>\n",
       "      <td>167.42</td>\n",
       "      <td>96.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-19 05:00:00</th>\n",
       "      <td>191.56</td>\n",
       "      <td>161.68</td>\n",
       "      <td>170.31</td>\n",
       "      <td>96.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-22 05:00:00</th>\n",
       "      <td>193.89</td>\n",
       "      <td>162.47</td>\n",
       "      <td>170.11</td>\n",
       "      <td>96.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-08 05:00:00</th>\n",
       "      <td>259.04</td>\n",
       "      <td>205.75</td>\n",
       "      <td>329.79</td>\n",
       "      <td>122.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-09 05:00:00</th>\n",
       "      <td>259.37</td>\n",
       "      <td>204.39</td>\n",
       "      <td>329.19</td>\n",
       "      <td>124.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-12 05:00:00</th>\n",
       "      <td>260.25</td>\n",
       "      <td>209.72</td>\n",
       "      <td>324.49</td>\n",
       "      <td>124.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-13 05:00:00</th>\n",
       "      <td>261.05</td>\n",
       "      <td>213.65</td>\n",
       "      <td>310.90</td>\n",
       "      <td>126.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-14 05:00:00</th>\n",
       "      <td>259.96</td>\n",
       "      <td>218.55</td>\n",
       "      <td>307.87</td>\n",
       "      <td>130.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ticker                 AAPL     JNJ     JPM     XOM\n",
       "timestamp                                          \n",
       "2024-01-16 05:00:00  183.63  160.52  167.99   97.69\n",
       "2024-01-17 05:00:00  182.68  160.43  167.09   96.98\n",
       "2024-01-18 05:00:00  188.63  161.21  167.42   96.80\n",
       "2024-01-19 05:00:00  191.56  161.68  170.31   96.95\n",
       "2024-01-22 05:00:00  193.89  162.47  170.11   96.82\n",
       "...                     ...     ...     ...     ...\n",
       "2026-01-08 05:00:00  259.04  205.75  329.79  122.91\n",
       "2026-01-09 05:00:00  259.37  204.39  329.19  124.61\n",
       "2026-01-12 05:00:00  260.25  209.72  324.49  124.03\n",
       "2026-01-13 05:00:00  261.05  213.65  310.90  126.54\n",
       "2026-01-14 05:00:00  259.96  218.55  307.87  130.20\n",
       "\n",
       "[502 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect data\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Comparison: Expected Returns (Annually) ---\n",
      "ticker\n",
      "AAPL    0.174843\n",
      "JNJ     0.155222\n",
      "JPM     0.304700\n",
      "XOM     0.144496\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- 2. EXPECTED RETURN (E[R]) ---\n",
    "# Calculate Log Returns: ln(P_t / P_{t-1})\n",
    "log_returns = np.log(df_pivot / df_pivot.shift(1)).dropna()\n",
    "\n",
    "# Method 1: Mathematical Definition E[X] = sum(X) / n\n",
    "expected_return_def = log_returns.sum() / len(log_returns)\n",
    "\n",
    "# Method 2: Python built-in function\n",
    "expected_return_func = log_returns.mean()\n",
    "\n",
    "print(\"--- Comparison: Expected Returns (Annually) ---\")\n",
    "print(expected_return_func * 252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Comparison: Volatility (Annually) ---\n",
      "ticker\n",
      "AAPL    0.276182\n",
      "JNJ     0.177937\n",
      "JPM     0.245571\n",
      "XOM     0.219428\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- 3. VARIANCE & STD DEV ---\n",
    "# Method 1: Mathematical Definition Var(X) = E[X^2] - (E[X])^2\n",
    "variance_def = (log_returns**2).mean() - (log_returns.mean())**2\n",
    "\n",
    "# Method 2: Python built-in function\n",
    "# Note: ddof=0 is used to match the population variance definition in math\n",
    "variance_func = log_returns.var(ddof=0)\n",
    "\n",
    "print(\"--- Comparison: Volatility (Annually) ---\")\n",
    "print(np.sqrt(variance_func) * np.sqrt(252))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Covariance Matrix ---\n",
      "ticker      AAPL       JNJ       JPM       XOM\n",
      "ticker                                        \n",
      "AAPL    0.000303  0.000008  0.000083  0.000056\n",
      "JNJ     0.000008  0.000126  0.000019  0.000024\n",
      "JPM     0.000083  0.000019  0.000240  0.000070\n",
      "XOM     0.000056  0.000024  0.000070  0.000191\n",
      "\n",
      "--- Correlation Matrix ---\n",
      "ticker      AAPL       JNJ       JPM       XOM\n",
      "ticker                                        \n",
      "AAPL    1.000000  0.039730  0.307609  0.233967\n",
      "JNJ     0.039730  1.000000  0.111412  0.157417\n",
      "JPM     0.307609  0.111412  1.000000  0.328261\n",
      "XOM     0.233967  0.157417  0.328261  1.000000\n"
     ]
    }
   ],
   "source": [
    "# --- 4. COVARIANCE & CORRELATION MATRIX ---\n",
    "# Calculate the Covariance Matrix\n",
    "cov_matrix = log_returns.cov()\n",
    "\n",
    "# Calculate the Correlation Matrix\n",
    "cor_matrix = log_returns.corr()\n",
    "\n",
    "print(\"\\n--- Covariance Matrix ---\")\n",
    "print(cov_matrix)\n",
    "print(\"\\n--- Correlation Matrix ---\")\n",
    "print(cor_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annualized Portfolio Volatility: 0.1476\n",
      "\n",
      "Individual Annualized Volatilities:\n",
      "[0.27645808 0.17811493 0.24581655 0.21964695]\n"
     ]
    }
   ],
   "source": [
    "# --- 5. PORTFOLIO RISK CALCULATION ---\n",
    "# Define weights (25% for each stock)\n",
    "weights = np.array([0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "# Formula: Var_p = w.T * Sigma * w\n",
    "portfolio_variance_daily = weights.T @ cov_matrix @ weights\n",
    "portfolio_volatility_daily = np.sqrt(portfolio_variance_daily)\n",
    "\n",
    "# Annualize the volatility\n",
    "portfolio_volatility_annual = portfolio_volatility_daily * np.sqrt(252)\n",
    "print(f\"Annualized Portfolio Volatility: {portfolio_volatility_annual:.4f}\")\n",
    "\n",
    "# Compare with individual volatilities\n",
    "individual_vols = np.sqrt(np.diag(cov_matrix)) * np.sqrt(252)\n",
    "print(\"\\nIndividual Annualized Volatilities:\")\n",
    "print(individual_vols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
